> val updateHistory =
>    //UpdateRecord("2024-06-20T17:50:00-04:00",Some("Add bold update crediting Maggie Appleton for some of these ideas."),Some("f22b4df6db0c2b09d42406fce93175d3fb7e1ed5")) ::
>    Nil
>
> val UntemplateAttributes = immutable.Map[String,Any] (
>   "Title"         -> "Zip-A-Dee-Doo-Dah",
>   "PubDate"       -> "2025-11-06T23:10:00-05:00",
>   "UpdateHistory" -> updateHistory,
>   "Anchor"        -> "zip-a-dee-doo-dah" // a String
> )

given PageBase = PageBase.fromPage(input.renderLocation)

(input : MainBlog.EntryInput)[]~()>      ### modify Title/Author/Pubdate above, add markdown or html below!

**TL; DR:** My two static sites (this site, [`drafts.interfluidity.com`](https://drafts.interfluidity.com/))
can now be downloaded in full as zip files, for offline reading or archiving. Zip download links: <a href="https://zip.interfluidity.com/tech/latest" download>tech</a>, <a href="https://zip.interfluidity.com/drafts/latest" download>drafts</a>

<div style="text-align: center">***</div>

Last week (during "[office hours](https://www.interfluidity.com/office-hours/)"), I was asked why I was so fond of static sites and static-site generators
for publishing writing. Aren't dynamic content management systems like WordPress or Drupal superior?

I really should have
an answer to this! I now [devote a large share of my time](https://github.com/swaldman/protopost) to an attempt to make static-site generation more
functional and accessible for less technical authors.

There are a lot of reasons to prefer static sites. About a month ago, the venerable blogging service TypePad
went down, and took with it the archives of some sites that are very important to me, like `economistsview.typepad.com`
and `stublingandmumbling.typepad.com`.

There is no point making those names links. The sites are gone. Every link to them is broken.

(All is not entirely lost. The author of `stublingandmumbling.typepad.com` has moved to a [substack](https://chrisdillow.substack.com/).)

If these had been static sites, their authors could have simply downloaded the sites in full (as a zip file or something like that),
and had them served from anywhere. Pretty much anything on the internet can serve a static site. Lots of services
will host static sites essentially for free. 

The infrastructure that serves static sites is the brainstem of the internet. WordPress constantly changes, is constantly
under attack. It and the database that backs it requires constant maintenance. A static site requires almost no maintenance
beyond keeping the web server that hosts it on the internet.

If you (1) have a static site, and (2) own the domain name for the site, then the site is yours. You can move it whenever you want, without breaking links.
In the age of the internet, it's so easy to "own" almost nothing. Everything is licensed, you are dependent on some vendor.
Even when it's possible, it's often costly and inconvenient to extricate yourself and reconstruct what you've lost.
Static sites, however, are freedom.

In addition to being movable, the fact that a static-site is basically a self-contained directory that can be wrapped
into a zip file offers benefits to readers, not just to the site's owner. Readers can, at least in theory, download the whole
site, for archiving purposes (including to keep the site publisher honest!), or to read the work offline.

I've been embarrassed by that "at least in theory". My static sites &mdash; this one, and
[`drafts.interfluidity.com`](https://drafts.interfluidity.com) &mdash; did not, in practice, make it easy for users
to download the full site. Technical users have always been able to do so, since
[both](https://github.com/swaldman/tech.interfluidity.com) [are](https://github.com/swaldman/drafts.interfluidity.com) hosted as public
git repositories. But there was nothing as simple as "download the site as a zip file".

So, now there is!

From the archive page of either site ([tech](##/archive.html), [drafts](https://drafts.interfluidity.com/archive.html)), there are now links to a zip file, which typically will
be updated nightly if there have been any changes. I've written
[scripts that maintain a zip directory](https://github.com/swaldman/mchange-sysadmin-scripts/tree/mchange-specific/taskbin) for each site,
that are hit every night by [systemd timers](https://github.com/swaldman/mchange-sysadmin-scripts/tree/mchange-specific/systemd),
and a [service](https://github.com/swaldman/latest-zips-tickle) that serves the latest zip it finds in those directories.
(As I [like to do](##library-plus-script-vs-application-plus-config-file), this service is a script backed by a [library](https://github.com/swaldman/latest),
with the script effectively serving as configuration for the library.)

The zip files behind the links update
themselves. The static sites need never change to stay current.

<div style="text-align: center">***</div>

p.s. Sometime soon I'd like also to offer more-convenient-for-offline-reading [epub files](https://en.wikipedia.org/wiki/EPUB).
The static sites now feature [full-content, all-item RSS](##supporting-all-item-rss), which should be a straightforward source for building those.
